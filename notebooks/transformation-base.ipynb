{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MOsHUjgdIrIW",
    "outputId": "f84a093e-147f-470e-aad9-80fb51193c8e"
   },
   "source": [
    "# Fine tuning T5-base summarization\n",
    "\n",
    "Base on code from https://github.com/huggingface/notebooks/blob/master/examples/summarization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working on a local system.\n",
      "Files will be searched relative to \"..\".\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    GIT_ROOT = 'https://github.com/furyhawk/text_summarization/raw/master'\n",
    "    os.system(f'wget {GIT_ROOT}/notebooks/setup.py')\n",
    "\n",
    "%run -i setup.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"$BASE_DIR/settings.py\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# to print output of all statements and not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# otherwise text between $ signs will be interpreted as formula and printed in italic\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "\n",
    "# path to import blueprints packages\n",
    "sys.path.append(BASE_DIR + '/packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets as well as other dependencies. Uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (4.11.3)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (3.6.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (1.21.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: dill in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (1.3.3)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.14 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (0.0.19)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (2021.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (2021.9.30)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from rouge-score) (0.14.0)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (4.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from pandas->datasets) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install datasets transformers rouge-score nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
    "\n",
    "To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n",
    "\n",
    "First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your username and password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you need to install Git-LFS. Uncomment the following instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt install git-lfs   # for linux\n",
    "# !git lfs install      # for windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BBC News summary dataset\n",
    "1.\tRemoval of newline from text elements.\n",
    "2.\tPartition the first line of the articles as title column.\n",
    "3.\tAligning the respective summary(label) with the news article(input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = f'../data/BBC News Summary'\n",
    "\n",
    "\n",
    "# root_path = f'/kaggle/input/bbc-news-summary/BBC News Summary'\n",
    "\n",
    "\n",
    "def loadDataset(root_path):\n",
    "\n",
    "    types_of_articles = ['business',\n",
    "                         'entertainment', 'politics', 'sport', 'tech']\n",
    "    df = pd.DataFrame(columns=['title', 'article', 'summary'])\n",
    "\n",
    "    for type_of_article in types_of_articles:\n",
    "        # type_of_article = 'business'  # entertainment, politices, sport, tech\n",
    "        num_of_article = len(os.listdir(\n",
    "            f\"{root_path}/News Articles/{type_of_article}\"))\n",
    "\n",
    "        print(f'\"Reading {type_of_article} articles\"')\n",
    "        dataframe = pd.DataFrame(columns=['title', 'article', 'summary'])\n",
    "\n",
    "        for i in tqdm(range(num_of_article)):\n",
    "            with open(f'{root_path}/News Articles/{type_of_article}/{(i+1):03d}.txt', 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "                article = f.read().partition(\"\\n\")\n",
    "            with open(f'{root_path}/Summaries/{type_of_article}/{(i+1):03d}.txt', 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "                summary = f.read()\n",
    "\n",
    "            dataframe.loc[i] = [article[0], article[2].replace(\n",
    "                '\\n', ' ').replace('\\r', ''), summary]\n",
    "\n",
    "        df = df.append(dataframe, ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'bbc.csv'\n",
    "\n",
    "if os.path.isfile(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "else:\n",
    "    df = loadDataset(root_path)\n",
    "    df.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Goo...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09b...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.  And Alan Greenspan highlighted the US g...</td>\n",
       "      <td>The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.China's currency remains pegged to the dol...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (£479m) loan.  State-owned Rosneft bought the Yugansk unit for $9.3bn in a s...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets.State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices for a 40% drop in profits.  Reporting its results for the three months to 31 December 2004, the airline made a pre-tax profit of £75m ($141m) compared ...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the results were \"respectable\" in a third quarter when fuel costs rose by £106m or 47.3%.To help offset the increased price of aviation fuel, BA last year...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.  Reports in the Wall Street Journal and the Financia...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.Shares in UK drinks and food firm Allied ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0  Ad sales boost Time Warner profit   \n",
       "1   Dollar gains on Greenspan speech   \n",
       "2  Yukos unit buyer faces loan claim   \n",
       "3  High fuel prices hit BA's profits   \n",
       "4  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                                                                                                                                                                                   article  \\\n",
       "0   Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Goo...   \n",
       "1   The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.  And Alan Greenspan highlighted the US g...   \n",
       "2   The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (£479m) loan.  State-owned Rosneft bought the Yugansk unit for $9.3bn in a s...   \n",
       "3   British Airways has blamed high fuel prices for a 40% drop in profits.  Reporting its results for the three months to 31 December 2004, the airline made a pre-tax profit of £75m ($141m) compared ...   \n",
       "4   Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.  Reports in the Wall Street Journal and the Financia...   \n",
       "\n",
       "                                                                                                                                                                                                   summary  \\\n",
       "0  TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09b...   \n",
       "1  The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.China's currency remains pegged to the dol...   \n",
       "2  Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets.State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part...   \n",
       "3  Rod Eddington, BA's chief executive, said the results were \"respectable\" in a third quarter when fuel costs rose by £106m or 47.3%.To help offset the increased price of aviation fuel, BA last year...   \n",
       "4  Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.Shares in UK drinks and food firm Allied ...   \n",
       "\n",
       "   category  \n",
       "0  business  \n",
       "1  business  \n",
       "2  business  \n",
       "3  business  \n",
       "4  business  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   title     2225 non-null   object\n",
      " 1   article   2225 non-null   object\n",
      " 2   summary   2225 non-null   object\n",
      " 3   category  2225 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('bbc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFASsisvIrIb"
   },
   "source": [
    "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/seq2seq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# Fine-tuning a model on a summarization task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTCFado4IrIc"
   },
   "source": [
    "In this notebook, we will see how to fine-tune one of the [🤗 Transformers](https://github.com/huggingface/transformers) model for a summarization task. We will use the [BBC dataset](https://www.kaggle.com/pariza/bbc-news-summary) which contains BBC News Summary.\n",
    "\n",
    "We will see how to easily load the dataset for this task using 🤗 Datasets and how to fine-tune a model on it using the `Trainer` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RRkXuteIrIh"
   },
   "source": [
    "This notebook is built to run  with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a sequence-to-sequence version in the Transformers library. Here we picked the [`t5-small`](https://huggingface.co/t5-small) checkpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [🤗 Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "raw_datasets = Dataset.from_pandas(df)  # Load from dataframe created earlier\n",
    "\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GWiVUF0jIrIv",
    "outputId": "35e3ea43-f397-4a54-c90c-f2cf8d36873e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'article', 'summary', 'category'],\n",
       "    num_rows: 2225\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'title': Value(dtype='string', id=None), 'article': Value(dtype='string', id=None), 'summary': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets.info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether to use news headline or summary as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_datasets = raw_datasets.remove_columns(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset in train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'article', 'summary', 'category'],\n",
       "        num_rows: 2002\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'article', 'summary', 'category'],\n",
       "        num_rows: 112\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['title', 'article', 'summary', 'category'],\n",
       "        num_rows: 111\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90% train, 10% test + validation\n",
    "train_testvalid = raw_datasets.train_test_split(test_size=0.1)\n",
    "# Split the 10% test + validation in half test, half validation\n",
    "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": train_testvalid[\"train\"],\n",
    "    \"test\": test_valid[\"test\"],\n",
    "    \"valid\": test_valid[\"train\"]})\n",
    "\n",
    "raw_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3EtYfeHIrIz"
   },
   "source": [
    "To access an actual element, you need to select a split first, then give an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "X6HrpprwIrIz",
    "outputId": "d7670bc0-42e4-4c09-8a6a-5c018ded7d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Monsanto fined $1.5m for bribery',\n",
       " 'article': ' The US agrochemical giant Monsanto has agreed to pay a $1.5m (£799,000) fine for bribing an Indonesian official.  Monsanto admitted one of its employees paid the senior official two years ago in a bid to avoid environmental impact studies being conducted on its cotton. In addition to the penalty, Monsanto also agreed to three years\\' close monitoring of its business practices by the American authorities. It said it accepted full responsibility for what it called improper activities.  A former senior manager at Monsanto directed an Indonesian consulting firm to give a $50,000 bribe to a high-level official in Indonesia\\'s environment ministry in 2002. The manager told the company to disguise an invoice for the bribe as \"consulting fees\".  Monsanto was facing stiff opposition from activists and farmers who were campaigning against its plans to introduce genetically-modified cotton in Indonesia. Despite the bribe, the official did not authorise the waiving of the environmental study requirement. Monsanto also has admitted to paying bribes to a number of other high-ranking officials between 1997 and 2002.  The chemicals-and-crops firm said it became aware of irregularities at a Jakarta-based subsidiary in 2001 and launched an internal investigation before informing the US Department of Justice and the Securities and Exchange Commission (SEC). Monsanto faced both criminal and civil charges from the Department of Justice and the SEC. \"Companies cannot bribe their way into favourable treatment by foreign officials,\" said Christopher Wray, assistant US attorney general. Monsanto has agreed to pay $1m to the Department of Justice, adopt internal compliance measures, and co-operate with continuing civil and criminal investigations. It is also paying $500,000 to the SEC to settle the bribe charge and other related violations. Monsanto said it accepted full responsibility for its employees\\' actions, adding that it had taken \"remedial actions to address the activities in Indonesia\" and had been \"fully co-operative\" throughout the investigative process. ',\n",
       " 'summary': \"Monsanto also has admitted to paying bribes to a number of other high-ranking officials between 1997 and 2002.A former senior manager at Monsanto directed an Indonesian consulting firm to give a $50,000 bribe to a high-level official in Indonesia's environment ministry in 2002.The US agrochemical giant Monsanto has agreed to pay a $1.5m (£799,000) fine for bribing an Indonesian official.Monsanto faced both criminal and civil charges from the Department of Justice and the SEC.Monsanto has agreed to pay $1m to the Department of Justice, adopt internal compliance measures, and co-operate with continuing civil and criminal investigations.Monsanto admitted one of its employees paid the senior official two years ago in a bid to avoid environmental impact studies being conducted on its cotton.\",\n",
       " 'category': 'business'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "SZy5tRB_IrI7",
    "outputId": "ba8f2124-e485-488f-8c0c-254f34f24f13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T in the Park sells out in days</td>\n",
       "      <td>Tickets for Scotland's biggest music festival have sold out in record time, five months before the event is held.  The 12th annual T in the Park festival, which takes place at Balado near Kinross in July, sold out just four days after the line-up was announced. Green Day, the Foo Fighters and Keane are among the acts that had already been lined up to appear at the event. However, the organisers have revealed Scots favourites Travis as well as soulman James Brown will also appear.  Last year tickets sold out 10 weeks before the festival but organisers confirmed that all 130,000 for the two-day event had been sold. Geoff Ellis, CEO of festival organisers Big Day Out Ltd, said this year's event promises to be the best yet. \"After last year's sell-out, we did think this year's event would sell slightly earlier, however this is way beyond our expectations,\" Mr Ellis said.  \"We are extremely proud that fans are so excited about T in the Park that they have made absolutely sure that their place at Balado is booked for 2005, and we will deliver one of the greatest events yet for them in July.\" More than 120 acts will play on eight stages over the weekend of 9 and 10 July. Brit Award winners Keane and The Streets are among the main attractions, while The Killers and dance act The Prodigy are also on the bill. Both Green Day and The Foo Fighters last played at the festival in 2002, the same year Oasis and Basement Jaxx were among the headline acts.</td>\n",
       "      <td>Green Day, the Foo Fighters and Keane are among the acts that had already been lined up to appear at the event.Geoff Ellis, CEO of festival organisers Big Day Out Ltd, said this year's event promises to be the best yet.Last year tickets sold out 10 weeks before the festival but organisers confirmed that all 130,000 for the two-day event had been sold.Both Green Day and The Foo Fighters last played at the festival in 2002, the same year Oasis and Basement Jaxx were among the headline acts.The 12th annual T in the Park festival, which takes place at Balado near Kinross in July, sold out just four days after the line-up was announced.</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deutsche Boerse boosts dividend</td>\n",
       "      <td>Deutsche Boerse, the German stock exchange that is trying to buy its London rival, has said it will boost its 2004 dividend payment by 27%.  Analysts said that the move is aimed at winning over investors opposed to its bid for the London Stock Exchange. Critics of the takeover have complained that the money could be better used by returning cash to shareholders. Deutsche Boerse also said profit in the three months to 31 December was 120.7m euros ($158.8m; £83.3m). Sales climbed to 364.4m euros, lifting revenue for the year to a record 1.45bn euros.  Frankfurt-based Deutsche Boerse has offered £1.3bn ($2.48bn; 1.88bn euros) for the London Stock Exchange. Rival pan-European bourse Euronext is working also on a bid. Late on Monday, Deutsche Boerse said it would lift its 2004 dividend payment to 70 euro cents (£0.48; $0.98) from 55 euro cents a year earlier. \"There is a whiff of a sweetener in there,\" Anais Faraj, an analyst at Nomura told the BBC's World Business Report. \"Most of the disgruntled shareholders of Deutsche Boerse are complaining that the money that is being used for the bid could be better placed in their hands, paid out in dividends,\" Mr Faraj continued. Deutsche Boerse is \"trying to buy them off in a sense\", he said.</td>\n",
       "      <td>Deutsche Boerse, the German stock exchange that is trying to buy its London rival, has said it will boost its 2004 dividend payment by 27%.Deutsche Boerse is \"trying to buy them off in a sense\", he said.\"Most of the disgruntled shareholders of Deutsche Boerse are complaining that the money that is being used for the bid could be better placed in their hands, paid out in dividends,\" Mr Faraj continued.Frankfurt-based Deutsche Boerse has offered £1.3bn ($2.48bn; 1.88bn euros) for the London Stock Exchange.Deutsche Boerse also said profit in the three months to 31 December was 120.7m euros ($158.8m; £83.3m).</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winter freeze keeps oil above $50</td>\n",
       "      <td>Oil prices carried on rising on Wednesday after cold weather on both sides of the North Atlantic pushed US crude prices to four-month highs.  Freezing temperatures and heavy snowfalls took crude oil prices past $50 a barrel on Tuesday for the first time since November. Declines in the dollar have also contributed to the rising oil price. US crude was trading at $51.39 at 0710 GMT in Asian electronic trade on Wednesday. A barrel of US crude oil closed up $2.80 at $51.15 in New York on Tuesday. Opec members said on Tuesday that, given such high prices, the cartel saw no reason to cut its output.  Although below last year's peak of $55.67 a barrel, which was reached in October, prices are now well above 2004's average of $41.48. Brent crude also rose in London trading, adding $1.89 to $48.62 at the close.  Much of western Europe and the north east of America has been shivering under unseasonably low temperatures in recent days. The decline in the US dollar to a five-week low against the euro has also served to inflate prices. \"The primary factor is the weak dollar,\" said Victor Shum, a Singapore-based analyst with Purvin and Gertz. Expectations that a rebound in the dollar would halt the oil price rise were not immediately borne out on Wednesday morning, as oil prices carried on upwards as the dollar strengthened against the euro, the pound and the yen.  Several Opec members said on Tuesday that a cut in production was unlikely, citing rising prices and strong demand for oil from Asia. \"I agree that we do not need to cut supply if the prices are as much as this,\" Fathi Bin Shatwan, Libya's oil minister, told Reuters. \"I do not think we need to cut unless the prices are falling below $35 a barrel,\" he added.</td>\n",
       "      <td>Oil prices carried on rising on Wednesday after cold weather on both sides of the North Atlantic pushed US crude prices to four-month highs.Declines in the dollar have also contributed to the rising oil price.Several Opec members said on Tuesday that a cut in production was unlikely, citing rising prices and strong demand for oil from Asia.Expectations that a rebound in the dollar would halt the oil price rise were not immediately borne out on Wednesday morning, as oil prices carried on upwards as the dollar strengthened against the euro, the pound and the yen.Freezing temperatures and heavy snowfalls took crude oil prices past $50 a barrel on Tuesday for the first time since November.A barrel of US crude oil closed up $2.80 at $51.15 in New York on Tuesday.</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown outlines third term vision</td>\n",
       "      <td>Gordon Brown has outlined what he thinks should be the key themes of New Labour's next general election bid.  He said ensuring every child in Britain had the best start in life could be a legacy to match the NHS's creation. The chancellor has previously planned the party's election strategy but this time the role will be filled by Alan Milburn - a key ally of Tony Blair. The premier insisted Mr Brown will have a key role in Labour's campaign, and praised his handling of the economy.  Writing in the Guardian newspaper, Mr Brown outlined his view of the direction New Labour should be taking. \"As our manifesto and our programme for the coming decade should make clear, Labour's ambition is not simply tackling idleness but delivering full employment; not just attacking ignorance, disease and squalor but promoting lifelong education, good health and sustainable communities.\" BBC political editor Andrew Marr said that Mr Brown's article was \"a warning shot\" to Mr Blair not to try and cut him out of the manifesto writing process. \"It was, as always, coded and careful... but entirely deliberate,\" was Mr Marr's assessment. The prime minister was asked about Mr Brown's article and about his election role when he appeared on BBC Radio 4's Today programme. Mr Blair said a decision had yet to be taken over how the election would be run but the chancellor's role would be \"central\". Mr Blair argued that under New Labour the country had changed for the better and that was \"in part\" because of Mr Brown's management of the economy. And he pledged childcare would be a \"centrepiece\" of Labour's manifesto. He also predicted the next general election will be a \"tough, tough fight\" for New Labour. But the prime minister insisted he did not know what date the poll would take place despite speculation about 5 May. Mr Blair said he was taking \"nothing for granted\" ahead of the vote - warning that the Tory strategy was to win power via the back door by hinting they were aiming to cut Labour's majority instead of hoping for an outright win.</td>\n",
       "      <td>BBC political editor Andrew Marr said that Mr Brown's article was \"a warning shot\" to Mr Blair not to try and cut him out of the manifesto writing process.Mr Blair argued that under New Labour the country had changed for the better and that was \"in part\" because of Mr Brown's management of the economy.Mr Blair said a decision had yet to be taken over how the election would be run but the chancellor's role would be \"central\".The prime minister was asked about Mr Brown's article and about his election role when he appeared on BBC Radio 4's Today programme.The premier insisted Mr Brown will have a key role in Labour's campaign, and praised his handling of the economy.Mr Blair said he was taking \"nothing for granted\" ahead of the vote - warning that the Tory strategy was to win power via the back door by hinting they were aiming to cut Labour's majority instead of hoping for an outright win.</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sluggish economy hits German jobs</td>\n",
       "      <td>The number of people out of work in Europe's largest economy has risen for the tenth straight month as growth remains stubbornly slow.  German unemployment rose 7,000 in November to 4.464 million people, or 10.8% of the workforce. The seasonally adjusted rise showed a smaller rise than expected, as government measures to encourage job creation began to take effect. But officials said stagnant growth was still stifling the job market. \"There are clear signs of a revival in domestic demand,\" said Frank-Juergen Weise, head of the Federal Labour Agency, in a statement. \"But growth of 0.1%... in the third quarter is still insufficient to deliver positive momentum to the labour market.\" High oil prices and the soaring euro - which damages the competitiveness of exporters - were also having a negative effect, he said. The brunt of the unemployment is still being felt in the eastern part of Germany, where the rate is 18.8%.  With unemployment stuck above 4 million for years, the government of Chancellor Gerhard Schroeder has put job creation at the top of the agenda. A controversial package of measures to shake up incentives to get back to work, paid for by cutting some cherished benefits, has sparked anger among some German workers. Strikes in a number of industries, notably among the country's iconic carmakers, have demonstrated the displeasure - as well as fears about further job losses as outsourcing takes hold. Among the new initiatives are the so-called \"one-euro jobs\" which top up unemployment benefit. The scheme's formal launch is January, but hirings for these positions are already taking place and affecting the unemployment statistics, economists said. \"The deterioration of the labour market does not come as a surprise,\" said Isabelle Kronawitter at Hypovereinsbank. \"Job creation measures probably prevented a stronger increase in the seasonally adjusted numbers.\"</td>\n",
       "      <td>But officials said stagnant growth was still stifling the job market.With unemployment stuck above 4 million for years, the government of Chancellor Gerhard Schroeder has put job creation at the top of the agenda.The seasonally adjusted rise showed a smaller rise than expected, as government measures to encourage job creation began to take effect.\"But growth of 0.1%... in the third quarter is still insufficient to deliver positive momentum to the labour market.\"\"Job creation measures probably prevented a stronger increase in the seasonally adjusted numbers.\"\"The deterioration of the labour market does not come as a surprise,\" said Isabelle Kronawitter at Hypovereinsbank.</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnjDIuQ3IrI-"
   },
   "source": [
    "The metric is an instance of [`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5o4rUteaIrI_",
    "outputId": "18038ef5-554c-45c5-e00a-133b02ec10f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metric(name: \"rouge\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: \"\"\"\n",
       "Calculates average rouge scores for a list of hypotheses and references\n",
       "Args:\n",
       "    predictions: list of predictions to score. Each predictions\n",
       "        should be a string with tokens separated by spaces.\n",
       "    references: list of reference for each prediction. Each\n",
       "        reference should be a string with tokens separated by spaces.\n",
       "    rouge_types: A list of rouge types to calculate.\n",
       "        Valid names:\n",
       "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
       "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
       "        `\"rougeLSum\"`: rougeLsum splits text using `\"\n",
       "\"`.\n",
       "        See details in https://github.com/huggingface/datasets/issues/617\n",
       "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
       "    use_agregator: Return aggregates if this is set to True\n",
       "Returns:\n",
       "    rouge1: rouge_1 (precision, recall, f1),\n",
       "    rouge2: rouge_2 (precision, recall, f1),\n",
       "    rougeL: rouge_l (precision, recall, f1),\n",
       "    rougeLsum: rouge_lsum (precision, recall, f1)\n",
       "Examples:\n",
       "\n",
       "    >>> rouge = datasets.load_metric('rouge')\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
       "    >>> print(results[\"rouge1\"])\n",
       "    AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n",
       "    >>> print(results[\"rouge1\"].mid.fmeasure)\n",
       "    1.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAWdqcUBIrJC"
   },
   "source": [
    "You can call its `compute` method with your predictions and labels, which need to be list of decoded strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6XN1Rq0aIrJC",
    "outputId": "a4405435-a8a9-41ff-9f79-a13077b587c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [\"hello there\", \"general kenobi\"]\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n",
    "\n",
    "To do all of this, instantiate tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- a tokenizer that corresponds to the model architecture used,\n",
    "- download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint) # t5-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "By default, the call above will use one of the fast tokenizers (backed by Rust) from the 🤗 Tokenizers library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "You can directly call this tokenizer on one sentence or a pair of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "a5hBlsrHIrJL",
    "outputId": "acdaa98a-a8cd-4a20-89b8-cc26437bbe90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [8774, 6, 48, 80, 7142, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this one sentence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the targets for our model, we need to tokenize them inside the `as_target_tokenizer` context manager. This will make sure the tokenizer uses the special tokens corresponding to the targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[8774, 6, 48, 80, 7142, 55, 1], [100, 19, 430, 7142, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁He', '▁didn', 't', '▁want', '▁to', '▁talk', '▁about', '▁cells', '▁on', '▁the', '▁cell', '▁phone', '▁because', '▁', 'he', '▁considered', '▁it', '▁boring', '</s>']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"He didnt want to talk about cells on the cell phone because he considered it boring\"\n",
    "inputs = tokenizer.encode(sentence, return_tensors='pt', add_special_tokens=True) # return PyTorch tensors\n",
    "tokens = tokenizer.convert_ids_to_tokens(list(inputs[0])) # Extract sample of batch index 0 from inputs list of lists\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "If you are using one of the five T5 checkpoints we have to prefix the inputs with \"summarize:\" (the model can also translate and it needs the prefix to know which task it has to perform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We can then write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # x var for summarization. Column article.\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets y. We are using column summary as label.\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-b70jh26IrJS",
    "outputId": "acd3a42d-985b-44ee-9daa-af5d944ce1d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21603, 10, 37, 837, 3, 9, 3844, 14676, 6079, 2963, 7, 288, 32, 65, 4686, 12, 726, 3, 9, 1514, 16593, 51, 41, 19853, 4440, 23938, 61, 1399, 21, 3, 2160, 115, 53, 46, 9995, 29, 2314, 5, 2963, 7, 288, 32, 10246, 80, 13, 165, 1652, 1866, 8, 2991, 2314, 192, 203, 977, 16, 3, 9, 6894, 12, 1792, 3262, 1113, 2116, 271, 4468, 30, 165, 7282, 5, 86, 811, 12, 8, 10736, 6, 2963, 7, 288, 32, 92, 4686, 12, 386, 203, 31, 885, 4891, 13, 165, 268, 2869, 57, 8, 797, 5779, 5, 94, 243, 34, 4307, 423, 3263, 21, 125, 34, 718, 22187, 1087, 5, 71, 1798, 2991, 2743, 44, 2963, 7, 288, 32, 6640, 46, 9995, 29, 9157, 1669, 12, 428, 3, 9, 29788, 3, 2160, 346, 12, 3, 9, 306, 18, 4563, 2314, 16, 9995, 31, 7, 1164, 8409, 16, 4407, 5, 37, 2743, 1219, 8, 349, 12, 31993, 46, 10921, 21, 8, 3, 2160, 346, 38, 96, 29492, 53, 3051, 1280, 2963, 7, 288, 32, 47, 5008, 14537, 8263, 45, 19053, 11, 7208, 113, 130, 2066, 53, 581, 165, 1390, 12, 4277, 6472, 1427, 18, 7360, 3676, 7282, 16, 9995, 5, 3, 4868, 8, 3, 2160, 346, 6, 8, 2314, 410, 59, 2291, 159, 15, 8, 8036, 23, 3745, 13, 8, 3262, 810, 5971, 5, 2963, 7, 288, 32, 92, 65, 10246, 12, 3788, 3, 2160, 346, 7, 12, 3, 9, 381, 13, 119, 306, 18, 6254, 53, 4298, 344, 6622, 11, 4407, 5, 37, 9356, 18, 232, 18, 2771, 102, 7, 1669, 243, 34, 1632, 2718, 13, 22085, 2197, 44, 3, 9, 31711, 18, 390, 20438, 16, 4402, 11, 3759, 46, 3224, 4962, 274, 16, 10454, 8, 837, 1775, 13, 6923, 11, 8, 20571, 11, 8231, 3527, 41, 134, 3073, 137, 2963, 7, 288, 32, 7865, 321, 4336, 11, 3095, 3991, 45, 8, 1775, 13, 6923, 11, 8, 180, 3073, 5, 96, 5890, 2837, 725, 1178, 3, 2160, 346, 70, 194, 139, 3, 30786, 1058, 57, 2959, 4298, 976, 243, 14702, 549, 2866, 6, 6165, 837, 4917, 879, 5, 2963, 7, 288, 32, 65, 4686, 12, 726, 1970, 51, 12, 8, 1775, 13, 6923, 6, 4693, 3224, 5856, 3629, 6, 11, 576, 18, 18140, 17, 15, 28, 6168, 3095, 11, 4336, 17032, 5, 94, 19, 92, 3788, 1514, 23221, 12, 8, 180, 3073, 12, 8955, 8, 3, 2160, 346, 1567, 11, 119, 1341, 17880, 5, 2963, 7, 288, 32, 243, 34, 4307, 423, 3263, 21, 165, 1652, 31, 2874, 6, 2651, 24, 34, 141, 1026, 96, 60, 8172, 40, 2874, 12, 1115, 8, 1087, 16, 9995, 121, 11, 141, 118, 96, 5195, 576, 18, 11480, 121, 1019, 8, 20184, 3268, 433, 5, 1], [21603, 10, 7190, 31, 7, 9637, 5072, 49, 3, 7, 20978, 326, 46, 13423, 9883, 12, 1369, 8, 1640, 51, 44, 1771, 31, 7, 19931, 1331, 1338, 5, 5072, 49, 3, 75, 11863, 4357, 4834, 3978, 12, 4081, 8, 1338, 1368, 11, 2369, 168, 2177, 13, 3434, 31, 7, 10290, 10689, 526, 6, 113, 14602, 8, 689, 16, 4357, 3708, 4220, 7, 5, 37, 296, 5297, 6336, 243, 10, 96, 196, 530, 12, 8, 3761, 11, 82, 9883, 47, 13423, 11, 27, 47, 29335, 5, 27, 966, 877, 234, 5, 96, 196, 1800, 3, 9, 385, 394, 1771, 1379, 68, 1500, 27, 31, 26, 163, 661, 16, 8, 711, 1964, 5, 37, 29, 762, 877, 3923, 535, 5072, 49, 6, 294, 13, 8, 1651, 7190, 314, 226, 2915, 51, 31395, 24, 751, 2045, 44, 8, 486, 3225, 7, 17793, 6, 56, 230, 919, 112, 1388, 12, 416, 1851, 31, 7, 30894, 3545, 1611, 25483, 10570, 16, 23826, 5, 96, 517, 757, 29, 27, 183, 341, 326, 18, 24814, 27, 214, 132, 19, 2500, 72, 16, 8, 5040, 11, 27, 1672, 12, 129, 3627, 16, 8, 416, 360, 1274, 976, 3, 88, 243, 5, 96, 196, 17, 31, 7, 131, 3, 9, 495, 13, 6591, 2462, 550, 38, 27, 43, 612, 16, 1767, 203, 11, 8, 772, 56, 369, 535, 8288, 31, 7, 15498, 2143, 11390, 47, 92, 16, 1041, 16, 19931, 5, 216, 3, 14417, 323, 45, 112, 14499, 15, 26, 4837, 51, 12, 2382, 51, 12, 1992, 1025, 16, 1401, 5, 5865, 4220, 7, 5, 3434, 31, 7, 10135, 1793, 7, 35, 19855, 751, 8, 1964, 16, 1401, 5, 4560, 4220, 7, 28, 10098, 348, 8643, 4049, 4011, 4524, 511, 16, 1401, 5, 3449, 4220, 7, 5, 290, 130, 2500, 13, 119, 2991, 2390, 9227, 2924, 70, 5297, 607, 147, 8, 1851, 5, 749, 51, 4890, 1640, 51, 23463, 52, 3, 75, 11863, 3, 9, 126, 1270, 1368, 13, 4306, 3916, 3978, 44, 3, 9, 1338, 16, 16491, 5, 37, 12371, 1201, 18, 1490, 3495, 8, 3946, 16, 160, 1678, 68, 141, 12, 8955, 21, 4494, 166, 286, 28, 1798, 22656, 6336, 23561, 21329, 9423, 16, 8, 804, 5, 3, 6, 113, 8238, 2400, 8, 1038, 3112, 44, 8, 11548, 5880, 336, 774, 6, 356, 46, 5297, 525, 200, 13, 10128, 1752, 51, 16, 8, 12063, 4418, 44, 3, 9, 1338, 16, 350, 107, 295, 5, 466, 14527, 3, 18, 6862, 75, 51, 710, 13, 18065, 4668, 446, 15311, 3, 26705, 23, 32, 31, 7, 1941, 3, 18, 47, 207, 631, 12, 9448, 21, 8, 1611, 25483, 7666, 7, 5, 486, 8, 337, 1338, 6, 2369, 1025, 16, 4306, 2555, 3978, 16, 3, 9, 306, 18, 4057, 887, 31, 7, 1640, 51, 5, 37, 605, 47, 751, 57, 1611, 9365, 3960, 21110, 3, 28150, 106, 13, 1410, 298, 15575, 8374, 6777, 961, 900, 49, 17, 47, 511, 5, 7190, 31, 7, 2194, 867, 5428, 76, 5667, 2369, 8486, 16, 4306, 2469, 5, 11548, 13467, 3, 107, 6707, 21774, 9365, 3350, 263, 3, 9, 731, 18, 4397, 1205, 12, 1041, 44, 46, 5297, 1338, 16, 15922, 5, 37, 2059, 18, 1201, 18, 1490, 13139, 1300, 3959, 51, 12, 1369, 8, 306, 4418, 11, 3, 17, 13296, 8808, 3840, 51, 16, 8, 887, 31, 7, 2538, 474, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2963, 7, 288, 32, 92, 65, 10246, 12, 3788, 3, 2160, 346, 7, 12, 3, 9, 381, 13, 119, 306, 18, 6254, 53, 4298, 344, 6622, 11, 4407, 5, 188, 1798, 2991, 2743, 44, 2963, 7, 288, 32, 6640, 46, 9995, 29, 9157, 1669, 12, 428, 3, 9, 29788, 3, 2160, 346, 12, 3, 9, 306, 18, 4563, 2314, 16, 9995, 31, 7, 1164, 8409, 16, 4407, 5, 634, 837, 3, 9, 3844, 14676, 6079, 2963, 7, 288, 32, 65, 4686, 12, 726, 3, 9, 1514, 16593, 51, 41, 19853, 4440, 23938, 61, 1399, 21, 3, 2160, 115, 53, 46, 9995, 29, 2314, 5, 9168, 7, 288, 32, 7865, 321, 4336, 11, 3095, 3991, 45, 8, 1775, 13, 6923, 11, 8, 180, 3073, 5, 9168, 7, 288, 1], [486, 8, 337, 1338, 6, 2369, 1025, 16, 4306, 2555, 3978, 16, 3, 9, 306, 18, 4057, 887, 31, 7, 1640, 51, 5, 21846, 537, 49, 3, 75, 11863, 4357, 4834, 3978, 12, 4081, 8, 1338, 1368, 11, 2369, 168, 2177, 13, 3434, 31, 7, 10290, 10689, 526, 6, 113, 14602, 8, 689, 16, 4357, 3708, 4220, 7, 5, 634, 296, 5297, 6336, 243, 10, 96, 196, 530, 12, 8, 3761, 11, 82, 9883, 47, 13423, 11, 27, 47, 29335, 5, 279, 10694, 77, 31, 7, 9637, 5072, 49, 3, 7, 20978, 326, 46, 13423, 9883, 12, 1369, 8, 1640, 51, 44, 1771, 31, 7, 19931, 1331, 1338, 5, 667, 120, 51, 6174, 13467, 3, 107, 6707, 21774, 9365, 3350, 263, 3, 9, 731, 18, 4397, 1205, 1]]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(raw_datasets['train'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "DDtsaJeVIrJT",
    "outputId": "aa4734bf-4ef5-4437-9948-2c16363da719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 2002, 'test': 112, 'valid': 111}\n"
     ]
    }
   ],
   "source": [
    "# raw_datasets['train'] = raw_datasets['train'].shard(num_shards=100, index=3)\n",
    "# raw_datasets['validation'] = raw_datasets['validation'].shard(num_shards=100, index=3)\n",
    "# raw_datasets['test'] = raw_datasets['test'].shard(num_shards=100, index=3)\n",
    "print(raw_datasets.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.28ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.13ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18.18ba/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that data is ready, download the pretrained model and fine-tune it. Since the task is of the sequence-to-sequence kind, use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "TlqNaB8jIrJW",
    "outputId": "84916cf3-6e6c-47f3-d081-032ec30a4132"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "Note that  we don't get a warning like in our classification example. This means we used all the weights of the pretrained model and there is no randomly initialized head in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "To instantiate a `Seq2SeqTrainer`, we will need to define three more things. The most important is the [`Seq2SeqTrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:\n",
    "\n",
    "batch_size 6 for 32GB of working memory.\n",
    "learning_rate change from 2e-5 to 3e-4 slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-bbc\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the cell and customize the weight decay. Since the `Seq2SeqTrainer` will save the model regularly and our dataset is quite large, we tell it to make three saves maximum. Lastly, we use the `predict_with_generate` option (to properly generate summaries) and activate mixed precision training (to go a bit faster).\n",
    "\n",
    "The last argument to setup everything so we can push the model to the [Hub](https://huggingface.co/models) regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the `hub_model_id` argument to set the repo name (it needs to be the full name, including your namespace: for instance `\"sgugger/t5-finetuned-xsum\"` or `\"huggingface/t5-finetuned-xsum\"`).\n",
    "\n",
    "Then, we need a special kind of data collator, which will not only pad the inputs to the maximum length in the batch, but also the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sZOdRlRIrJd"
   },
   "source": [
    "The last thing to define for our `Seq2SeqTrainer` is how to compute the metrics from the predictions. We need to define a function for this, which will just use the `metric` we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "UmvbnJ9JIrJd"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\workspace\\text_summarization\\notebooks\\t5-base-finetuned-bbc is already a clone of https://huggingface.co/furyhawk/t5-base-finetuned-bbc. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\furyx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: title, summary, category, article.\n",
      "***** Running training *****\n",
      "  Num examples = 2002\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 334\n",
      "100%|██████████| 334/334 [4:24:29<00:00, 44.91s/it]The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: title, summary, category, article.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 111\n",
      "  Batch size = 6\n",
      "\n",
      "100%|██████████| 334/334 [4:32:03<00:00, 44.91s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 334/334 [4:32:03<00:00, 48.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15001356601715088, 'eval_rouge1': 24.5024, 'eval_rouge2': 21.4979, 'eval_rougeL': 24.0227, 'eval_rougeLsum': 24.0303, 'eval_gen_len': 19.0, 'eval_runtime': 453.564, 'eval_samples_per_second': 0.245, 'eval_steps_per_second': 0.042, 'epoch': 1.0}\n",
      "{'train_runtime': 16323.2352, 'train_samples_per_second': 0.123, 'train_steps_per_second': 0.02, 'train_loss': 0.2580676507093235, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=334, training_loss=0.2580676507093235, metrics={'train_runtime': 16323.2352, 'train_samples_per_second': 0.123, 'train_steps_per_second': 0.02, 'train_loss': 0.2580676507093235, 'epoch': 1.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the trained model to Hugging Face Hub,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5-base-finetuned-bbc\n",
      "Configuration saved in t5-base-finetuned-bbc\\config.json\n",
      "Model weights saved in t5-base-finetuned-bbc\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-base-finetuned-bbc\\tokenizer_config.json\n",
      "Special tokens file saved in t5-base-finetuned-bbc\\special_tokens_map.json\n",
      "Copy vocab file to t5-base-finetuned-bbc\\spiece.model\n",
      "Upload file pytorch_model.bin:  99%|█████████▉| 846M/850M [00:55<00:00, 16.7MB/s]To https://huggingface.co/furyhawk/t5-base-finetuned-bbc\n",
      "   f587d43..a4aea5b  main -> main\n",
      "\n",
      "Upload file pytorch_model.bin: 100%|██████████| 850M/850M [00:57<00:00, 15.5MB/s]\n",
      "Upload file training_args.bin: 100%|██████████| 2.86k/2.86k [00:56<?, ?B/s]\n",
      "Dropping the following result as it does not have all the necessary field:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
      "To https://huggingface.co/furyhawk/t5-base-finetuned-bbc\n",
      "   a4aea5b..40bcfef  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/furyhawk/t5-base-finetuned-bbc/commit/a4aea5bd182542131d6a776d728e8fb4094114e0'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `\"your-username/the-name-you-picked\"` so for instance:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"sgugger/my-awesome-model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Summarization",
   "provenance": []
  },
  "interpreter": {
   "hash": "9a7204dd9f60bd662761bdbb6f90c481306084606f9758a59a17813579c978f3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
