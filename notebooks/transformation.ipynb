{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MOsHUjgdIrIW",
    "outputId": "f84a093e-147f-470e-aad9-80fb51193c8e"
   },
   "source": [
    "# Fine tuning T5-small summarization\n",
    "\n",
    "Base on code from https://github.com/huggingface/notebooks/blob/master/examples/summarization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working on a local system.\n",
      "Files will be searched relative to \"..\".\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    GIT_ROOT = 'https://github.com/furyhawk/text_summarization/raw/master'\n",
    "    os.system(f'wget {GIT_ROOT}/notebooks/setup.py')\n",
    "\n",
    "%run -i setup.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"$BASE_DIR/settings.py\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# to print output of all statements and not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# otherwise text between $ signs will be interpreted as formula and printed in italic\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "\n",
    "# path to import blueprints packages\n",
    "sys.path.append(BASE_DIR + '/packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers and ðŸ¤— Datasets as well as other dependencies. Uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-1.14.0-py3-none-any.whl (290 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (4.11.2)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (3.6.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.19 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (0.0.19)\n",
      "Requirement already satisfied: packaging in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (1.3.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (2021.10.1)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (6.0.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (1.21.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: dill in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (2021.9.30)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from rouge-score) (0.14.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.19->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\furyx\\miniconda3\\envs\\text\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Installing collected packages: datasets\n",
      "Successfully installed datasets-1.14.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install datasets transformers rouge-score nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
    "\n",
    "To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n",
    "\n",
    "First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your username and password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you need to install Git-LFS. Uncomment the following instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt install git-lfs   # for linux\n",
    "# !git lfs install      # for windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/jessevig/bertviz.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BBC News summary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = f'../data/BBC News Summary'\n",
    "\n",
    "\n",
    "# root_path = f'/kaggle/input/bbc-news-summary/BBC News Summary'\n",
    "\n",
    "\n",
    "def loadDataset(root_path):\n",
    "\n",
    "    types_of_articles = ['business',\n",
    "                         'entertainment', 'politics', 'sport', 'tech']\n",
    "    df = pd.DataFrame(columns=['title', 'article', 'summary'])\n",
    "\n",
    "    for type_of_article in types_of_articles:\n",
    "        # type_of_article = 'business'  # entertainment, politices, sport, tech\n",
    "        num_of_article = len(os.listdir(\n",
    "            f\"{root_path}/News Articles/{type_of_article}\"))\n",
    "\n",
    "        print(f'\"Reading {type_of_article} articles\"')\n",
    "        dataframe = pd.DataFrame(columns=['title', 'article', 'summary'])\n",
    "\n",
    "        for i in tqdm(range(num_of_article)):\n",
    "            with open(f'{root_path}/News Articles/{type_of_article}/{(i+1):03d}.txt', 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "                article = f.read().partition(\"\\n\")\n",
    "            with open(f'{root_path}/Summaries/{type_of_article}/{(i+1):03d}.txt', 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "                summary = f.read()\n",
    "\n",
    "            dataframe.loc[i] = [article[0], article[2].replace(\n",
    "                '\\n', ' ').replace('\\r', ''), summary]\n",
    "\n",
    "        df = df.append(dataframe, ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if dataset has already been saved, read from cvs if yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Reading business articles\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 510/510 [00:36<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Reading entertainment articles\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:27<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Reading politics articles\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 417/417 [00:28<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Reading sport articles\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 511/511 [00:36<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Reading tech articles\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 401/401 [00:28<00:00, 14.25it/s]\n"
     ]
    }
   ],
   "source": [
    "fname = 'bbc.csv'\n",
    "\n",
    "if os.path.isfile(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "else:\n",
    "    df = loadDataset(root_path)\n",
    "    df.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TitleAd sales boost Time Warner profit\n",
      "article Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.  Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.  Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.  TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake. \n",
      "summaryTimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn.Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues.Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.Time Warner's fourth quarter profits were slightly better than analysts' expectations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_text = df['title'][0]\n",
    "print( 'Title' + sample_text)\n",
    "sample_text = df['article'][0]\n",
    "print( 'article' + sample_text)\n",
    "sample_text = df['summary'][0]\n",
    "print( 'summary' + sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Goo...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.  And Alan Greenspan highlighted the US g...</td>\n",
       "      <td>The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.China's currency remains pegged to the dol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan.  State-owned Rosneft bought the Yugansk unit for $9.3bn in a s...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets.State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices for a 40% drop in profits.  Reporting its results for the three months to 31 December 2004, the airline made a pre-tax profit of Â£75m ($141m) compared ...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the results were \"respectable\" in a third quarter when fuel costs rose by Â£106m or 47.3%.To help offset the increased price of aviation fuel, BA last year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.  Reports in the Wall Street Journal and the Financia...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.Shares in UK drinks and food firm Allied ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0  Ad sales boost Time Warner profit   \n",
       "1   Dollar gains on Greenspan speech   \n",
       "2  Yukos unit buyer faces loan claim   \n",
       "3  High fuel prices hit BA's profits   \n",
       "4  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                                                                                                                                                                                   article  \\\n",
       "0   Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Goo...   \n",
       "1   The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.  And Alan Greenspan highlighted the US g...   \n",
       "2   The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan.  State-owned Rosneft bought the Yugansk unit for $9.3bn in a s...   \n",
       "3   British Airways has blamed high fuel prices for a 40% drop in profits.  Reporting its results for the three months to 31 December 2004, the airline made a pre-tax profit of Â£75m ($141m) compared ...   \n",
       "4   Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.  Reports in the Wall Street Journal and the Financia...   \n",
       "\n",
       "                                                                                                                                                                                                   summary  \n",
       "0  TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09b...  \n",
       "1  The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.China's currency remains pegged to the dol...  \n",
       "2  Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets.State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part...  \n",
       "3  Rod Eddington, BA's chief executive, said the results were \"respectable\" in a third quarter when fuel costs rose by Â£106m or 47.3%.To help offset the increased price of aviation fuel, BA last year...  \n",
       "4  Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.Shares in UK drinks and food firm Allied ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  2225 non-null   int64 \n",
      " 1   title       2225 non-null   object\n",
      " 2   article     2225 non-null   object\n",
      " 3   summary     2225 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFASsisvIrIb"
   },
   "source": [
    "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/seq2seq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# Fine-tuning a model on a summarization task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTCFado4IrIc"
   },
   "source": [
    "In this notebook, we will see how to fine-tune one of the [ðŸ¤— Transformers](https://github.com/huggingface/transformers) model for a summarization task. We will use the [BBC dataset](https://www.kaggle.com/pariza/bbc-news-summary) which contains BBC News Summary.\n",
    "\n",
    "We will see how to easily load the dataset for this task using ðŸ¤— Datasets and how to fine-tune a model on it using the `Trainer` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RRkXuteIrIh"
   },
   "source": [
    "This notebook is built to run  with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a sequence-to-sequence version in the Transformers library. Here we picked the [`t5-small`](https://huggingface.co/t5-small) checkpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [ðŸ¤— Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "raw_datasets = Dataset.from_pandas(df)  # Load from dataframe created earlier\n",
    "\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GWiVUF0jIrIv",
    "outputId": "35e3ea43-f397-4a54-c90c-f2cf8d36873e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'article', 'summary'],\n",
       "    num_rows: 2225\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'title': Value(dtype='string', id=None), 'article': Value(dtype='string', id=None), 'summary': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets.info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether to use news headline or summary as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_datasets = raw_datasets.remove_columns(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset in train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'article', 'summary'],\n",
       "        num_rows: 2002\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'article', 'summary'],\n",
       "        num_rows: 112\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['title', 'article', 'summary'],\n",
       "        num_rows: 111\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90% train, 10% test + validation\n",
    "train_testvalid = raw_datasets.train_test_split(test_size=0.1)\n",
    "# Split the 10% test + validation in half test, half validation\n",
    "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "raw_datasets = DatasetDict({\n",
    "    \"train\": train_testvalid[\"train\"],\n",
    "    \"test\": test_valid[\"test\"],\n",
    "    \"valid\": test_valid[\"train\"]})\n",
    "\n",
    "raw_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3EtYfeHIrIz"
   },
   "source": [
    "To access an actual element, you need to select a split first, then give an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "X6HrpprwIrIz",
    "outputId": "d7670bc0-42e4-4c09-8a6a-5c018ded7d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': \"Monsanto also has admitted to paying bribes to a number of other high-ranking officials between 1997 and 2002.A former senior manager at Monsanto directed an Indonesian consulting firm to give a $50,000 bribe to a high-level official in Indonesia's environment ministry in 2002.The US agrochemical giant Monsanto has agreed to pay a $1.5m (Â£799,000) fine for bribing an Indonesian official.Monsanto faced both criminal and civil charges from the Department of Justice and the SEC.Monsanto has agreed to pay $1m to the Department of Justice, adopt internal compliance measures, and co-operate with continuing civil and criminal investigations.Monsanto admitted one of its employees paid the senior official two years ago in a bid to avoid environmental impact studies being conducted on its cotton.\",\n",
       " 'title': 'Monsanto fined $1.5m for bribery',\n",
       " 'article': ' The US agrochemical giant Monsanto has agreed to pay a $1.5m (Â£799,000) fine for bribing an Indonesian official.  Monsanto admitted one of its employees paid the senior official two years ago in a bid to avoid environmental impact studies being conducted on its cotton. In addition to the penalty, Monsanto also agreed to three years\\' close monitoring of its business practices by the American authorities. It said it accepted full responsibility for what it called improper activities.  A former senior manager at Monsanto directed an Indonesian consulting firm to give a $50,000 bribe to a high-level official in Indonesia\\'s environment ministry in 2002. The manager told the company to disguise an invoice for the bribe as \"consulting fees\".  Monsanto was facing stiff opposition from activists and farmers who were campaigning against its plans to introduce genetically-modified cotton in Indonesia. Despite the bribe, the official did not authorise the waiving of the environmental study requirement. Monsanto also has admitted to paying bribes to a number of other high-ranking officials between 1997 and 2002.  The chemicals-and-crops firm said it became aware of irregularities at a Jakarta-based subsidiary in 2001 and launched an internal investigation before informing the US Department of Justice and the Securities and Exchange Commission (SEC). Monsanto faced both criminal and civil charges from the Department of Justice and the SEC. \"Companies cannot bribe their way into favourable treatment by foreign officials,\" said Christopher Wray, assistant US attorney general. Monsanto has agreed to pay $1m to the Department of Justice, adopt internal compliance measures, and co-operate with continuing civil and criminal investigations. It is also paying $500,000 to the SEC to settle the bribe charge and other related violations. Monsanto said it accepted full responsibility for its employees\\' actions, adding that it had taken \"remedial actions to address the activities in Indonesia\" and had been \"fully co-operative\" throughout the investigative process. '}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SZy5tRB_IrI7",
    "outputId": "ba8f2124-e485-488f-8c0c-254f34f24f13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ocean's Twelve raids box office</td>\n",
       "      <td>Ocean's Twelve, the crime caper sequel starring George Clooney, Brad Pitt and Julia Roberts, has gone straight to number one in the US box office chart.  It took $40.8m (Â£21m) in weekend ticket sales, according to studio estimates. The sequel follows the master criminals as they try to pull off three major heists across Europe. It knocked last week's number one, National Treasure, into third place. Wesley Snipes' Blade: Trinity was in second, taking $16.1m (Â£8.4m). Rounding out the top five was animated fable The Polar Express, starring Tom Hanks, and festive comedy Christmas with the Kranks.  Ocean's Twelve box office triumph marks the fourth-biggest opening for a December release in the US, after the three films in the Lord of the Rings trilogy. The sequel narrowly beat its 2001 predecessor, Ocean's Eleven which took $38.1m (Â£19.8m) on its opening weekend and $184m (Â£95.8m) in total. A remake of the 1960s film, starring Frank Sinatra and the Rat Pack, Ocean's Eleven was directed by Oscar-winning director Steven Soderbergh. Soderbergh returns to direct the hit sequel which reunites Clooney, Pitt and Roberts with Matt Damon, Andy Garcia and Elliott Gould. Catherine Zeta-Jones joins the all-star cast. \"It's just a fun, good holiday movie,\" said Dan Fellman, president of distribution at Warner Bros. However, US critics were less complimentary about the $110m (Â£57.2m) project, with the Los Angeles Times labelling it a \"dispiriting vanity project\". A milder review in the New York Times dubbed the sequel \"unabashedly trivial\".</td>\n",
       "      <td>Ocean's Twelve, the crime caper sequel starring George Clooney, Brad Pitt and Julia Roberts, has gone straight to number one in the US box office chart.The sequel narrowly beat its 2001 predecessor, Ocean's Eleven which took $38.1m (Â£19.8m) on its opening weekend and $184m (Â£95.8m) in total.A remake of the 1960s film, starring Frank Sinatra and the Rat Pack, Ocean's Eleven was directed by Oscar-winning director Steven Soderbergh.Ocean's Twelve box office triumph marks the fourth-biggest opening for a December release in the US, after the three films in the Lord of the Rings trilogy.Soderbergh returns to direct the hit sequel which reunites Clooney, Pitt and Roberts with Matt Damon, Andy Garcia and Elliott Gould.A milder review in the New York Times dubbed the sequel \"unabashedly trivial\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kilroy-Silk quits 'shameful' UKIP</td>\n",
       "      <td>Ex-chat show host Robert Kilroy-Silk has quit the UK Independence Party and accused it of betraying its supporters.  The MEP said he was ashamed to have joined the party, which he labelled as a \"joke\". He plans to stand in the next general election but refused to confirm he is setting up a new political party called Veritas - Latin for truth. UKIP leader Roger Knapman said he would \"break open the champagne\", adding: \"It was nice knowing him, now 'goodbye'.\" However, he did say the ex-chat show host had been \"quite useful initially\". \"He has remarkable ability to influence people but, sadly, after the (European) election it became clear that he was more interested in the Robert Kilroy-Silk Party than the UK Independence Party so it was nice knowing him, now 'goodbye',\" Mr Knapman told BBC Radio 4's Today programme. Mr Knapman rejected the idea Mr Kilroy-Silk posed a threat to UKIP and queried why he had failed to confirm rumours he was starting a new political party.  Mr Kilroy-Silk explained his reasons to his East Midlands constituents at a meeting in Hinckley, Leicestershire. His decision came as UKIP officials began a process which could have triggered Mr Kilroy-Silk's expulsion. It marks the end of his membership of UKIP after just nine months. It began with a flood of publicity which helped UKIP into third place in last June's European elections but became dominated by rancour as he tried to take over the party leadership.  Mr Kilroy-Silk accused his fellow UKIP MEPs of being content with growing fat \"sitting on their backsides\" in Brussels. He told BBC News 24: \"I tried to change the party, I nagged all the way through the summer to do things, to get moving because I thought it was criminal what they were doing, it was a betrayal.\" Mr Kilroy-Silk also told Sky News there was \"masses of support\" for him to form a new party - something he has yet to confirm will happen.  UKIP won 12 seats and 16.1% of the vote at the European elections on the back of its call for the UK to leave the European Union In his speech, Mr Kilroy-Silk says the result offered UKIP an \"amazing opportunity\" but the party's leadership had done nothing and \"gone AWOL\". There were no policies, no energy, no vision and no spokespeople, he said. \"The party is going nowhere and I'm embarrassed with its allies in Europe and I'm ashamed to be a member of the party,\" said Mr Kilroy-Silk.  He said his conviction in Britain's right to govern itself had not changed. He would continue that campaign outside UKIP when he contested the general election in an East Midlands constituency. Reports of his new party plans have prompted a formal complaint to UKIP's disciplinary committee for bringing the party into \"disrepute\". On Thursday, the party challenged Mr Kilroy-Silk to stand down as an MEP so voters can get a genuine UKIP candidate.</td>\n",
       "      <td>Mr Knapman rejected the idea Mr Kilroy-Silk posed a threat to UKIP and queried why he had failed to confirm rumours he was starting a new political party.\"He has remarkable ability to influence people but, sadly, after the (European) election it became clear that he was more interested in the Robert Kilroy-Silk Party than the UK Independence Party so it was nice knowing him, now 'goodbye',\" Mr Knapman told BBC Radio 4's Today programme.On Thursday, the party challenged Mr Kilroy-Silk to stand down as an MEP so voters can get a genuine UKIP candidate.\"The party is going nowhere and I'm embarrassed with its allies in Europe and I'm ashamed to be a member of the party,\" said Mr Kilroy-Silk.Mr Kilroy-Silk also told Sky News there was \"masses of support\" for him to form a new party - something he has yet to confirm will happen.The MEP said he was ashamed to have joined the party, which he labelled as a \"joke\".Ex-chat show host Robert Kilroy-Silk has quit the UK Independence Party and accused it of betraying its supporters.UKIP won 12 seats and 16.1% of the vote at the European elections on the back of its call for the UK to leave the European Union In his speech, Mr Kilroy-Silk says the result offered UKIP an \"amazing opportunity\" but the party's leadership had done nothing and \"gone AWOL\".Mr Kilroy-Silk accused his fellow UKIP MEPs of being content with growing fat \"sitting on their backsides\" in Brussels.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highbury tunnel players in clear</td>\n",
       "      <td>The Football Association has said it will not be bringing charges over the tunnel incident prior to the Arsenal and Manchester United game.  Arsenal's Patrick Vieira had earlier denied accusations that he threatened Gary Neville before the 4-2 defeat. Vieira also clashed with opposing skipper Roy Keane and referee Graham Poll had to separate them. \"The referee has confirmed that he is satisfied he dealt with the incident at the time,\" said an FA statement. It means United's win will pass off without further intervention from the governing body, whose new chief executive Brian Barwick was in the Highbury stands.  \"I didn't threaten anybody. They are big enough players to handle themselves,\" said Vieira. \"I had a talk with Roy Keane and that's it. Gary Neville is a big lad, he can handle himself. \"They just played better than us and deserved to win.\" Neville admitted there had been incidents before the game, but insisted it had not distracted his focus. \"There were a couple of things that did happen before the game which disappoint you,\" he said. \"Especially from players of that calibre, but it's a tough game and we've been around a long time.\" Neville admitted that he had not enjoyed the match, which was punctuated by fouls and the sending off of Mikael Silvestre for head-butting Freddie Ljungberg . \"I thought it was a horrible game in the first half, and it was not much better in the second,\" he said. \"There is no way that should have happened in a football match.\"  After the match, Keane accused Vieira of starting the row. \"Patrick Vieira is 6ft 4in and having a go at Gary Neville. So I said, 'have a go at me',\" he said. \"If he wants to intimidate our players and thinks that Gary Neville is an easy target, I'm not having it.\" Manchester United manager Sir Alex Ferguson added: \"Vieira was well wound up for it. \"I've heard different stories. Patrick Vieira has apparently threatened some of our players and things like that.\"</td>\n",
       "      <td>They are big enough players to handle themselves,\" said Vieira.\"Patrick Vieira is 6ft 4in and having a go at Gary Neville.Arsenal's Patrick Vieira had earlier denied accusations that he threatened Gary Neville before the 4-2 defeat.\"I thought it was a horrible game in the first half, and it was not much better in the second,\" he said.Patrick Vieira has apparently threatened some of our players and things like that.\"The Football Association has said it will not be bringing charges over the tunnel incident prior to the Arsenal and Manchester United game.So I said, 'have a go at me',\" he said.After the match, Keane accused Vieira of starting the row.\"There were a couple of things that did happen before the game which disappoint you,\" he said.Gary Neville is a big lad, he can handle himself.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ebbers 'aware' of WorldCom fraud</td>\n",
       "      <td>Former WorldCom boss Bernie Ebbers was directly involved in the $11bn financial fraud at the firm, his closest associate has told a US court.  Giving evidence in the criminal trial of Mr Ebbers, ex-finance chief Scott Sullivan implicated his colleague in the accounting scandal at the firm. Mr Sullivan, WorldCom's former number two, is the government's chief witness in its case against Mr Ebbers. Mr Ebbers has denied multiple charges of conspiracy and fraud.  Senior WorldCom executives are accused of orchestrating a huge fraud at the former telecoms company in which they exaggerated revenues and hid the cost of expenses. The firm was forced into bankruptcy, the largest in US history. Mr Sullivan, 42, pleaded guilty to fraud last year and agreed to assist the government with its case against Mr Ebbers.  Prosecutors have alleged that Mr Ebbers, 63, directed Mr Sullivan to hide the true state of the company's finances by providing false information to the firm's accountants. Mr Ebbers has denied all the charges, saying he was unaware of the fraud. His lawyers claim that their client was unfamiliar with detailed accounting practices and left that side of the business to Mr Sullivan.  However, on Monday Mr Sullivan named Mr Ebbers as one of five executives who participated in the accounting fraud. \"He [Ebbers] has got a hands-on grasp of financial information,\" Mr Sullivan told a New York court. On his first day of questioning, Mr Sullivan admitted to falsifying the company's financial statements.  \"We did not disclose these adjustments,\" he said. \"We did not talk about these adjustments and the information was false.\" Mr Sullivan said his former boss knew more about accounting matters than many chief financial officers and described him as \"detail-oriented\".  He portrayed Mr Ebbers, a charismatic businessman who built up WorldCom from a small regional operator into one of America's largest telecoms firms, as obsessed with costs. \"He would talk about that there were more coffee filters than coffee bags and that means employees are taking coffee home,\" he said. \"We needed to cut expenses. We needed to cut a lot more than coffee expenses.\" Mr Sullivan is at the centre of the government's case against Mr Ebbers. Mr Ebbers could face a sentence of 85 years if convicted of all the charges he is facing.</td>\n",
       "      <td>Mr Sullivan is at the centre of the government's case against Mr Ebbers.However, on Monday Mr Sullivan named Mr Ebbers as one of five executives who participated in the accounting fraud.Mr Sullivan, WorldCom's former number two, is the government's chief witness in its case against Mr Ebbers.Mr Sullivan, 42, pleaded guilty to fraud last year and agreed to assist the government with its case against Mr Ebbers.Mr Ebbers has denied all the charges, saying he was unaware of the fraud.Prosecutors have alleged that Mr Ebbers, 63, directed Mr Sullivan to hide the true state of the company's finances by providing false information to the firm's accountants.Mr Ebbers has denied multiple charges of conspiracy and fraud.\"He [Ebbers] has got a hands-on grasp of financial information,\" Mr Sullivan told a New York court.Mr Sullivan said his former boss knew more about accounting matters than many chief financial officers and described him as \"detail-oriented\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>God cut from Dark Materials film</td>\n",
       "      <td>The director and screenwriter of the film adaptation of Philip Pullman's His Dark Materials is to remove references to God and the church in the movie.  Chris Weitz, director of About a Boy, said the changes were being made after film studio New Line expressed concern. The books tell of a battle against the church and a fight to overthrow God. \"They have expressed worry about the possibility of perceived anti-religiosity,\" Weitz told a His Dark Materials fans' website. Pullman's trilogy has been attacked by some Christian teachers and by the Catholic press as blasphemy. Weitz, who admitted he would not be many people's first choice to direct the films, said he regarded the film adaptation as \"the most important work of my life\".  \"In part because it is one of the few books to have changed my life,\" he told bridgetothestars.net. The award-winning trilogy - Northern Lights, The Subtle Knife and The Amber Spyglass - tell the story of Oxford school child Lyra Belacqua. She is drawn into an epic struggle against the Church, which has been carrying out experiments on children in an attempt to remove original sin.  As the books progress the struggle turns into a battle to overthrow the Authority, a figure who is God-like in the books. Weitz, who directed American Pie and About A Boy, said New Line feared that any anti-religiosity in the film would make the project \"unviable financially\". He said: \"All my best efforts will be directed towards keeping the film as liberating and iconoclastic an experience as I can. \"But there may be some modification of terms.\"  Weitz said he had visited Pullman, who had told him that the Authority could \"represent any arbitrary establishment that curtails the freedom of the individual, whether it be religious, political, totalitarian, fundamentalist, communist, what have you\". He added: \"I have no desire to change the nature or intentions of the villains of the piece, but they may appear in more subtle guises.\" There are a number of Christian websites which attack the trilogy for their depiction of the church and of God, but Pullman has denied his books are anti-religious. His agent told the Times newspaper that Pullman was happy with the adaptation so far. \"Of course New Line want to make money, but Mr Weitz is a wonderful director and Philip is very supportive. \"You have to recognise that it is a challenge in the climate of Bush's America,\"</td>\n",
       "      <td>Chris Weitz, director of About a Boy, said the changes were being made after film studio New Line expressed concern.There are a number of Christian websites which attack the trilogy for their depiction of the church and of God, but Pullman has denied his books are anti-religious.The director and screenwriter of the film adaptation of Philip Pullman's His Dark Materials is to remove references to God and the church in the movie.Weitz, who directed American Pie and About A Boy, said New Line feared that any anti-religiosity in the film would make the project \"unviable financially\".The books tell of a battle against the church and a fight to overthrow God.Weitz, who admitted he would not be many people's first choice to direct the films, said he regarded the film adaptation as \"the most important work of my life\".\"They have expressed worry about the possibility of perceived anti-religiosity,\" Weitz told a His Dark Materials fans' website.Weitz said he had visited Pullman, who had told him that the Authority could \"represent any arbitrary establishment that curtails the freedom of the individual, whether it be religious, political, totalitarian, fundamentalist, communist, what have you\".</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnjDIuQ3IrI-"
   },
   "source": [
    "The metric is an instance of [`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5o4rUteaIrI_",
    "outputId": "18038ef5-554c-45c5-e00a-133b02ec10f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metric(name: \"rouge\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: \"\"\"\n",
       "Calculates average rouge scores for a list of hypotheses and references\n",
       "Args:\n",
       "    predictions: list of predictions to score. Each predictions\n",
       "        should be a string with tokens separated by spaces.\n",
       "    references: list of reference for each prediction. Each\n",
       "        reference should be a string with tokens separated by spaces.\n",
       "    rouge_types: A list of rouge types to calculate.\n",
       "        Valid names:\n",
       "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
       "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
       "        `\"rougeLSum\"`: rougeLsum splits text using `\"\n",
       "\"`.\n",
       "        See details in https://github.com/huggingface/datasets/issues/617\n",
       "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
       "    use_agregator: Return aggregates if this is set to True\n",
       "Returns:\n",
       "    rouge1: rouge_1 (precision, recall, f1),\n",
       "    rouge2: rouge_2 (precision, recall, f1),\n",
       "    rougeL: rouge_l (precision, recall, f1),\n",
       "    rougeLsum: rouge_lsum (precision, recall, f1)\n",
       "Examples:\n",
       "\n",
       "    >>> rouge = datasets.load_metric('rouge')\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
       "    >>> print(results[\"rouge1\"])\n",
       "    AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n",
       "    >>> print(results[\"rouge1\"].mid.fmeasure)\n",
       "    1.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAWdqcUBIrJC"
   },
   "source": [
    "You can call its `compute` method with your predictions and labels, which need to be list of decoded strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6XN1Rq0aIrJC",
    "outputId": "a4405435-a8a9-41ff-9f79-a13077b587c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [\"hello there\", \"general kenobi\"]\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint) # t5-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "By default, the call above will use one of the fast tokenizers (backed by Rust) from the ðŸ¤— Tokenizers library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "Load some required javascript libraries for displaying visualization in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "You can directly call this tokenizer on one sentence or a pair of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "a5hBlsrHIrJL",
    "outputId": "acdaa98a-a8cd-4a20-89b8-cc26437bbe90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [8774, 6, 48, 80, 7142, 55, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this one sentence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the targets for our model, we need to tokenize them inside the `as_target_tokenizer` context manager. This will make sure the tokenizer uses the special tokens corresponding to the targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[8774, 6, 48, 80, 7142, 55, 1], [100, 19, 430, 7142, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â–He', 'â–didn', 't', 'â–want', 'â–to', 'â–talk', 'â–about', 'â–cells', 'â–on', 'â–the', 'â–cell', 'â–phone', 'â–because', 'â–', 'he', 'â–considered', 'â–it', 'â–boring', '</s>']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"He didnt want to talk about cells on the cell phone because he considered it boring\"\n",
    "inputs = tokenizer.encode(sentence, return_tensors='pt', add_special_tokens=True) # return PyTorch tensors\n",
    "tokens = tokenizer.convert_ids_to_tokens(list(inputs[0])) # Extract sample of batch index 0 from inputs list of lists\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "If you are using one of the five T5 checkpoints we have to prefix the inputs with \"summarize:\" (the model can also translate and it needs the prefix to know which task it has to perform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We can then write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # x var for summarization. Column article.\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets y. We are using column summary as label.\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "-b70jh26IrJS",
    "outputId": "acd3a42d-985b-44ee-9daa-af5d944ce1d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[21603, 10, 37, 837, 3, 9, 3844, 14676, 6079, 2963, 7, 288, 32, 65, 4686, 12, 726, 3, 9, 1514, 16593, 51, 41, 19853, 4440, 23938, 61, 1399, 21, 3, 2160, 115, 53, 46, 9995, 29, 2314, 5, 2963, 7, 288, 32, 10246, 80, 13, 165, 1652, 1866, 8, 2991, 2314, 192, 203, 977, 16, 3, 9, 6894, 12, 1792, 3262, 1113, 2116, 271, 4468, 30, 165, 7282, 5, 86, 811, 12, 8, 10736, 6, 2963, 7, 288, 32, 92, 4686, 12, 386, 203, 31, 885, 4891, 13, 165, 268, 2869, 57, 8, 797, 5779, 5, 94, 243, 34, 4307, 423, 3263, 21, 125, 34, 718, 22187, 1087, 5, 71, 1798, 2991, 2743, 44, 2963, 7, 288, 32, 6640, 46, 9995, 29, 9157, 1669, 12, 428, 3, 9, 29788, 3, 2160, 346, 12, 3, 9, 306, 18, 4563, 2314, 16, 9995, 31, 7, 1164, 8409, 16, 4407, 5, 37, 2743, 1219, 8, 349, 12, 31993, 46, 10921, 21, 8, 3, 2160, 346, 38, 96, 29492, 53, 3051, 1280, 2963, 7, 288, 32, 47, 5008, 14537, 8263, 45, 19053, 11, 7208, 113, 130, 2066, 53, 581, 165, 1390, 12, 4277, 6472, 1427, 18, 7360, 3676, 7282, 16, 9995, 5, 3, 4868, 8, 3, 2160, 346, 6, 8, 2314, 410, 59, 2291, 159, 15, 8, 8036, 23, 3745, 13, 8, 3262, 810, 5971, 5, 2963, 7, 288, 32, 92, 65, 10246, 12, 3788, 3, 2160, 346, 7, 12, 3, 9, 381, 13, 119, 306, 18, 6254, 53, 4298, 344, 6622, 11, 4407, 5, 37, 9356, 18, 232, 18, 2771, 102, 7, 1669, 243, 34, 1632, 2718, 13, 22085, 2197, 44, 3, 9, 31711, 18, 390, 20438, 16, 4402, 11, 3759, 46, 3224, 4962, 274, 16, 10454, 8, 837, 1775, 13, 6923, 11, 8, 20571, 11, 8231, 3527, 41, 134, 3073, 137, 2963, 7, 288, 32, 7865, 321, 4336, 11, 3095, 3991, 45, 8, 1775, 13, 6923, 11, 8, 180, 3073, 5, 96, 5890, 2837, 725, 1178, 3, 2160, 346, 70, 194, 139, 3, 30786, 1058, 57, 2959, 4298, 976, 243, 14702, 549, 2866, 6, 6165, 837, 4917, 879, 5, 2963, 7, 288, 32, 65, 4686, 12, 726, 1970, 51, 12, 8, 1775, 13, 6923, 6, 4693, 3224, 5856, 3629, 6, 11, 576, 18, 18140, 17, 15, 28, 6168, 3095, 11, 4336, 17032, 5, 94, 19, 92, 3788, 1514, 23221, 12, 8, 180, 3073, 12, 8955, 8, 3, 2160, 346, 1567, 11, 119, 1341, 17880, 5, 2963, 7, 288, 32, 243, 34, 4307, 423, 3263, 21, 165, 1652, 31, 2874, 6, 2651, 24, 34, 141, 1026, 96, 60, 8172, 40, 2874, 12, 1115, 8, 1087, 16, 9995, 121, 11, 141, 118, 96, 5195, 576, 18, 11480, 121, 1019, 8, 20184, 3268, 433, 5, 1], [21603, 10, 7190, 31, 7, 9637, 5072, 49, 3, 7, 20978, 326, 46, 13423, 9883, 12, 1369, 8, 1640, 51, 44, 1771, 31, 7, 19931, 1331, 1338, 5, 5072, 49, 3, 75, 11863, 4357, 4834, 3978, 12, 4081, 8, 1338, 1368, 11, 2369, 168, 2177, 13, 3434, 31, 7, 10290, 10689, 526, 6, 113, 14602, 8, 689, 16, 4357, 3708, 4220, 7, 5, 37, 296, 5297, 6336, 243, 10, 96, 196, 530, 12, 8, 3761, 11, 82, 9883, 47, 13423, 11, 27, 47, 29335, 5, 27, 966, 877, 234, 5, 96, 196, 1800, 3, 9, 385, 394, 1771, 1379, 68, 1500, 27, 31, 26, 163, 661, 16, 8, 711, 1964, 5, 37, 29, 762, 877, 3923, 535, 5072, 49, 6, 294, 13, 8, 1651, 7190, 314, 226, 2915, 51, 31395, 24, 751, 2045, 44, 8, 486, 3225, 7, 17793, 6, 56, 230, 919, 112, 1388, 12, 416, 1851, 31, 7, 30894, 3545, 1611, 25483, 10570, 16, 23826, 5, 96, 517, 757, 29, 27, 183, 341, 326, 18, 24814, 27, 214, 132, 19, 2500, 72, 16, 8, 5040, 11, 27, 1672, 12, 129, 3627, 16, 8, 416, 360, 1274, 976, 3, 88, 243, 5, 96, 196, 17, 31, 7, 131, 3, 9, 495, 13, 6591, 2462, 550, 38, 27, 43, 612, 16, 1767, 203, 11, 8, 772, 56, 369, 535, 8288, 31, 7, 15498, 2143, 11390, 47, 92, 16, 1041, 16, 19931, 5, 216, 3, 14417, 323, 45, 112, 14499, 15, 26, 4837, 51, 12, 2382, 51, 12, 1992, 1025, 16, 1401, 5, 5865, 4220, 7, 5, 3434, 31, 7, 10135, 1793, 7, 35, 19855, 751, 8, 1964, 16, 1401, 5, 4560, 4220, 7, 28, 10098, 348, 8643, 4049, 4011, 4524, 511, 16, 1401, 5, 3449, 4220, 7, 5, 290, 130, 2500, 13, 119, 2991, 2390, 9227, 2924, 70, 5297, 607, 147, 8, 1851, 5, 749, 51, 4890, 1640, 51, 23463, 52, 3, 75, 11863, 3, 9, 126, 1270, 1368, 13, 4306, 3916, 3978, 44, 3, 9, 1338, 16, 16491, 5, 37, 12371, 1201, 18, 1490, 3495, 8, 3946, 16, 160, 1678, 68, 141, 12, 8955, 21, 4494, 166, 286, 28, 1798, 22656, 6336, 23561, 21329, 9423, 16, 8, 804, 5, 3, 6, 113, 8238, 2400, 8, 1038, 3112, 44, 8, 11548, 5880, 336, 774, 6, 356, 46, 5297, 525, 200, 13, 10128, 1752, 51, 16, 8, 12063, 4418, 44, 3, 9, 1338, 16, 350, 107, 295, 5, 466, 14527, 3, 18, 6862, 75, 51, 710, 13, 18065, 4668, 446, 15311, 3, 26705, 23, 32, 31, 7, 1941, 3, 18, 47, 207, 631, 12, 9448, 21, 8, 1611, 25483, 7666, 7, 5, 486, 8, 337, 1338, 6, 2369, 1025, 16, 4306, 2555, 3978, 16, 3, 9, 306, 18, 4057, 887, 31, 7, 1640, 51, 5, 37, 605, 47, 751, 57, 1611, 9365, 3960, 21110, 3, 28150, 106, 13, 1410, 298, 15575, 8374, 6777, 961, 900, 49, 17, 47, 511, 5, 7190, 31, 7, 2194, 867, 5428, 76, 5667, 2369, 8486, 16, 4306, 2469, 5, 11548, 13467, 3, 107, 6707, 21774, 9365, 3350, 263, 3, 9, 731, 18, 4397, 1205, 12, 1041, 44, 46, 5297, 1338, 16, 15922, 5, 37, 2059, 18, 1201, 18, 1490, 13139, 1300, 3959, 51, 12, 1369, 8, 306, 4418, 11, 3, 17, 13296, 8808, 3840, 51, 16, 8, 887, 31, 7, 2538, 474, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[2963, 7, 288, 32, 92, 65, 10246, 12, 3788, 3, 2160, 346, 7, 12, 3, 9, 381, 13, 119, 306, 18, 6254, 53, 4298, 344, 6622, 11, 4407, 5, 188, 1798, 2991, 2743, 44, 2963, 7, 288, 32, 6640, 46, 9995, 29, 9157, 1669, 12, 428, 3, 9, 29788, 3, 2160, 346, 12, 3, 9, 306, 18, 4563, 2314, 16, 9995, 31, 7, 1164, 8409, 16, 4407, 5, 634, 837, 3, 9, 3844, 14676, 6079, 2963, 7, 288, 32, 65, 4686, 12, 726, 3, 9, 1514, 16593, 51, 41, 19853, 4440, 23938, 61, 1399, 21, 3, 2160, 115, 53, 46, 9995, 29, 2314, 5, 9168, 7, 288, 32, 7865, 321, 4336, 11, 3095, 3991, 45, 8, 1775, 13, 6923, 11, 8, 180, 3073, 5, 9168, 7, 288, 1], [486, 8, 337, 1338, 6, 2369, 1025, 16, 4306, 2555, 3978, 16, 3, 9, 306, 18, 4057, 887, 31, 7, 1640, 51, 5, 21846, 537, 49, 3, 75, 11863, 4357, 4834, 3978, 12, 4081, 8, 1338, 1368, 11, 2369, 168, 2177, 13, 3434, 31, 7, 10290, 10689, 526, 6, 113, 14602, 8, 689, 16, 4357, 3708, 4220, 7, 5, 634, 296, 5297, 6336, 243, 10, 96, 196, 530, 12, 8, 3761, 11, 82, 9883, 47, 13423, 11, 27, 47, 29335, 5, 279, 10694, 77, 31, 7, 9637, 5072, 49, 3, 7, 20978, 326, 46, 13423, 9883, 12, 1369, 8, 1640, 51, 44, 1771, 31, 7, 19931, 1331, 1338, 5, 667, 120, 51, 6174, 13467, 3, 107, 6707, 21774, 9365, 3350, 263, 3, 9, 731, 18, 4397, 1205, 1]]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(raw_datasets['train'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DDtsaJeVIrJT",
    "outputId": "aa4734bf-4ef5-4437-9948-2c16363da719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 2002, 'test': 112, 'valid': 111}\n"
     ]
    }
   ],
   "source": [
    "# raw_datasets['train'] = raw_datasets['train'].shard(num_shards=100, index=3)\n",
    "# raw_datasets['validation'] = raw_datasets['validation'].shard(num_shards=100, index=3)\n",
    "# raw_datasets['test'] = raw_datasets['test'].shard(num_shards=100, index=3)\n",
    "print(raw_datasets.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de7f8c286c049e29cd44a68cc8910d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2956f4319c4e789689500f1dc40e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9dbad059c4476f9f561baa1c95a686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "Even better, the results are automatically cached by the ðŸ¤— Datasets library to avoid spending time on this step the next time you run your notebook. The ðŸ¤— Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ðŸ¤— Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TlqNaB8jIrJW",
    "outputId": "84916cf3-6e6c-47f3-d081-032ec30a4132"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "Note that  we don't get a warning like in our classification example. This means we used all the weights of the pretrained model and there is no randomly initialized head in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "To instantiate a `Seq2SeqTrainer`, we will need to define three more things. The most important is the [`Seq2SeqTrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-bbc\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the cell and customize the weight decay. Since the `Seq2SeqTrainer` will save the model regularly and our dataset is quite large, we tell it to make three saves maximum. Lastly, we use the `predict_with_generate` option (to properly generate summaries) and activate mixed precision training (to go a bit faster).\n",
    "\n",
    "The last argument to setup everything so we can push the model to the [Hub](https://huggingface.co/models) regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the `hub_model_id` argument to set the repo name (it needs to be the full name, including your namespace: for instance `\"sgugger/t5-finetuned-xsum\"` or `\"huggingface/t5-finetuned-xsum\"`).\n",
    "\n",
    "Then, we need a special kind of data collator, which will not only pad the inputs to the maximum length in the batch, but also the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sZOdRlRIrJd"
   },
   "source": [
    "The last thing to define for our `Seq2SeqTrainer` is how to compute the metrics from the predictions. We need to define a function for this, which will just use the `metric` we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "UmvbnJ9JIrJd"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt') # initial nltk download\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W:\\workspace\\text_summarization\\notebooks\\t5-small-finetuned-bbc is already a clone of https://huggingface.co/furyhawk/t5-small-finetuned-bbc. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "uNx5pyRlIrJh",
    "outputId": "077e661e-d36c-469b-89b8-7ff7f73541ec"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  236354 KB |  236354 KB |  236354 KB |       0 B  |\\n|       from large pool |  162560 KB |  162560 KB |  162560 KB |       0 B  |\\n|       from small pool |   73794 KB |   73794 KB |   73794 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  236354 KB |  236354 KB |  236354 KB |       0 B  |\\n|       from large pool |  162560 KB |  162560 KB |  162560 KB |       0 B  |\\n|       from small pool |   73794 KB |   73794 KB |   73794 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  243712 KB |  243712 KB |  243712 KB |       0 B  |\\n|       from large pool |  167936 KB |  167936 KB |  167936 KB |       0 B  |\\n|       from small pool |   75776 KB |   75776 KB |   75776 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    7358 KB |   19709 KB |  122111 KB |  114753 KB |\\n|       from large pool |    5376 KB |   17664 KB |   83200 KB |   77824 KB |\\n|       from small pool |    1982 KB |    2047 KB |   38911 KB |   36929 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     131    |     131    |     131    |       0    |\\n|       from large pool |      25    |      25    |      25    |       0    |\\n|       from small pool |     106    |     106    |     106    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     131    |     131    |     131    |       0    |\\n|       from large pool |      25    |      25    |      25    |       0    |\\n|       from small pool |     106    |     106    |     106    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      43    |      43    |      43    |       0    |\\n|       from large pool |       6    |       6    |       6    |       0    |\\n|       from small pool |      37    |      37    |      37    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       4    |       4    |      43    |      39    |\\n|       from large pool |       2    |       2    |       6    |       4    |\\n|       from small pool |       2    |       2    |      37    |      35    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "# del variables\n",
    "gc.collect()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, title, article.\n",
      "***** Running training *****\n",
      "  Num examples = 2002\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1001' max='1001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1001/1001 06:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.488200</td>\n",
       "      <td>0.323812</td>\n",
       "      <td>21.226600</td>\n",
       "      <td>16.092700</td>\n",
       "      <td>19.678500</td>\n",
       "      <td>19.884900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5-small-finetuned-bbc\\checkpoint-500\n",
      "Configuration saved in t5-small-finetuned-bbc\\checkpoint-500\\config.json\n",
      "Model weights saved in t5-small-finetuned-bbc\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-finetuned-bbc\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-finetuned-bbc\\checkpoint-500\\special_tokens_map.json\n",
      "tokenizer config file saved in t5-small-finetuned-bbc\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-finetuned-bbc\\special_tokens_map.json\n",
      "Deleting older checkpoint [t5-small-finetuned-bbc\\checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to t5-small-finetuned-bbc\\checkpoint-1000\n",
      "Configuration saved in t5-small-finetuned-bbc\\checkpoint-1000\\config.json\n",
      "Model weights saved in t5-small-finetuned-bbc\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-finetuned-bbc\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-finetuned-bbc\\checkpoint-1000\\special_tokens_map.json\n",
      "Deleting older checkpoint [t5-small-finetuned-bbc\\checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: summary, title, article.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 111\n",
      "  Batch size = 2\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1001, training_loss=0.6741910312440131, metrics={'train_runtime': 384.3744, 'train_samples_per_second': 5.208, 'train_steps_per_second': 2.604, 'total_flos': 400159183208448.0, 'train_loss': 0.6741910312440131, 'epoch': 1.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now upload the result of the training to the Hub, just execute this instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to t5-small-finetuned-bbc\n",
      "Configuration saved in t5-small-finetuned-bbc\\config.json\n",
      "Model weights saved in t5-small-finetuned-bbc\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-finetuned-bbc\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-finetuned-bbc\\special_tokens_map.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec66d5114a73439198b32243e8d87a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 3.36k/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3abebcfdff4579a25407345016b50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Oct29_18-54-01_ALIENMEDIA/events.out.tfevents.1635504852.ALIENMEDIA.6320.0:  67%|######6   | â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/furyhawk/t5-small-finetuned-bbc\n",
      "   6c9ad8d..2b4559c  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 21.2266}]}\n",
      "To https://huggingface.co/furyhawk/t5-small-finetuned-bbc\n",
      "   2b4559c..9dfd6be  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/furyhawk/t5-small-finetuned-bbc/commit/2b4559c91b0a0a31965dd90fd8928245ce4f4274'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `\"your-username/the-name-you-picked\"` so for instance:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"sgugger/my-awesome-model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Summarization",
   "provenance": []
  },
  "interpreter": {
   "hash": "5caea8df2d6b3afe4c6a8fa5e4ec8aa952f5ed6f914beaca74edf16901303bb7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('text': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
