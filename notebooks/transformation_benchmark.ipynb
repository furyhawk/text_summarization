{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MOsHUjgdIrIW",
    "outputId": "f84a093e-147f-470e-aad9-80fb51193c8e"
   },
   "source": [
    "# Fine tuning T5 summarization\n",
    "\n",
    "Base on code from https://github.com/huggingface/notebooks/blob/master/examples/summarization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working on a local system.\n",
      "Files will be searched relative to \"..\".\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    GIT_ROOT = 'https://github.com/furyhawk/text_summarization/raw/master'\n",
    "    os.system(f'wget {GIT_ROOT}/notebooks/setup.py')\n",
    "\n",
    "%run -i setup.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"$BASE_DIR/settings.py\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# to print output of all statements and not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# otherwise text between $ signs will be interpreted as formula and printed in italic\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "\n",
    "# path to import blueprints packages\n",
    "sys.path.append(BASE_DIR + '/packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers and ðŸ¤— Datasets as well as other dependencies. Uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! pip install datasets transformers rouge-score nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
    "\n",
    "To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n",
    "\n",
    "First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your username and password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you need to install Git-LFS. Uncomment the following instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rouge_score import rouge_scorer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from nltk import tokenize\n",
    "# import matplotlib.pyplot as plt\n",
    "# import html\n",
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BBC News summary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = f'../data/BBC News Summary'\n",
    "\n",
    "\n",
    "# root_path = f'/kaggle/input/bbc-news-summary/BBC News Summary'\n",
    "\n",
    "\n",
    "def loadDataset(root_path):\n",
    "\n",
    "    types_of_articles = ['business',\n",
    "                         'entertainment', 'politics', 'sport', 'tech']\n",
    "    df = pd.DataFrame(columns=['title', 'article', 'summary'])\n",
    "\n",
    "    for type_of_article in types_of_articles:\n",
    "        # type_of_article = 'business'  # entertainment, politices, sport, tech\n",
    "        num_of_article = len(os.listdir(\n",
    "            f\"{root_path}/News Articles/{type_of_article}\"))\n",
    "\n",
    "        print(f'\"Reading {type_of_article} articles\"')\n",
    "        dataframe = pd.DataFrame(columns=['title', 'article', 'summary'])\n",
    "\n",
    "        for i in tqdm(range(num_of_article)):\n",
    "            with open(f'{root_path}/News Articles/{type_of_article}/{(i+1):03d}.txt', 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "                article = f.read().partition(\"\\n\")\n",
    "            with open(f'{root_path}/Summaries/{type_of_article}/{(i+1):03d}.txt', 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "                summary = f.read()\n",
    "\n",
    "            dataframe.loc[i] = [article[0], article[2].replace(\n",
    "                '\\n', ' ').replace('\\r', ''), summary]\n",
    "\n",
    "        df = df.append(dataframe, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'bbc.csv'\n",
    "\n",
    "if os.path.isfile(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "else:\n",
    "    df = loadDataset(root_path)\n",
    "    df.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TitleAd sales boost Time Warner profit\n",
      "article Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.  Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.  Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.  TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake. \n",
      "summaryTimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn.Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues.Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.Time Warner's fourth quarter profits were slightly better than analysts' expectations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_text = df['title'][0]\n",
    "print( 'Title' + sample_text)\n",
    "sample_text = df['article'][0]\n",
    "print( 'article' + sample_text)\n",
    "sample_text = df['summary'][0]\n",
    "print( 'summary' + sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Goo...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09b...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.  And Alan Greenspan highlighted the US g...</td>\n",
       "      <td>The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.China's currency remains pegged to the dol...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan.  State-owned Rosneft bought the Yugansk unit for $9.3bn in a s...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets.State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices for a 40% drop in profits.  Reporting its results for the three months to 31 December 2004, the airline made a pre-tax profit of Â£75m ($141m) compared ...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the results were \"respectable\" in a third quarter when fuel costs rose by Â£106m or 47.3%.To help offset the increased price of aviation fuel, BA last year...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.  Reports in the Wall Street Journal and the Financia...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.Shares in UK drinks and food firm Allied ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0  Ad sales boost Time Warner profit   \n",
       "1   Dollar gains on Greenspan speech   \n",
       "2  Yukos unit buyer faces loan claim   \n",
       "3  High fuel prices hit BA's profits   \n",
       "4  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                                                                                                                                                                                   article  \\\n",
       "0   Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.  The firm, which is now one of the biggest investors in Goo...   \n",
       "1   The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.  And Alan Greenspan highlighted the US g...   \n",
       "2   The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan.  State-owned Rosneft bought the Yugansk unit for $9.3bn in a s...   \n",
       "3   British Airways has blamed high fuel prices for a 40% drop in profits.  Reporting its results for the three months to 31 December 2004, the airline made a pre-tax profit of Â£75m ($141m) compared ...   \n",
       "4   Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.  Reports in the Wall Street Journal and the Financia...   \n",
       "\n",
       "                                                                                                                                                                                                   summary  \\\n",
       "0  TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn.For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09b...   \n",
       "1  The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.China's currency remains pegged to the dol...   \n",
       "2  Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets.State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part...   \n",
       "3  Rod Eddington, BA's chief executive, said the results were \"respectable\" in a third quarter when fuel costs rose by Â£106m or 47.3%.To help offset the increased price of aviation fuel, BA last year...   \n",
       "4  Pernod has reduced the debt it took on to fund the Seagram purchase to just 1.8bn euros, while Allied has improved the performance of its fast-food chains.Shares in UK drinks and food firm Allied ...   \n",
       "\n",
       "   category  \n",
       "0  business  \n",
       "1  business  \n",
       "2  business  \n",
       "3  business  \n",
       "4  business  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   title     2225 non-null   object\n",
      " 1   article   2225 non-null   object\n",
      " 2   summary   2225 non-null   object\n",
      " 3   category  2225 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 69.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('bbc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFASsisvIrIb"
   },
   "source": [
    "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/seq2seq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# Fine-tuning a model on a summarization task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTCFado4IrIc"
   },
   "source": [
    "In this notebook, we will see how to fine-tune one of the [ðŸ¤— Transformers](https://github.com/huggingface/transformers) model for a summarization task. We will use the [BBC dataset](https://www.kaggle.com/pariza/bbc-news-summary) which contains BBC News Summary.\n",
    "\n",
    "We will see how to easily load the dataset for this task using ðŸ¤— Datasets and how to fine-tune a model on it using the `Trainer` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RRkXuteIrIh"
   },
   "source": [
    "This notebook is built to run  with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a sequence-to-sequence version in the Transformers library. Here we picked the [`t5-small`](https://huggingface.co/t5-small) checkpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [ðŸ¤— Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "raw_datasets = Dataset.from_pandas(df)  # Load from dataframe created earlier\n",
    "\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GWiVUF0jIrIv",
    "outputId": "35e3ea43-f397-4a54-c90c-f2cf8d36873e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'article', 'summary', 'category'],\n",
       "    num_rows: 2225\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'title': Value(dtype='string', id=None), 'article': Value(dtype='string', id=None), 'summary': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets.info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether to use news headline or summary as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_datasets = raw_datasets.remove_columns(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset in train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'article', 'summary', 'category'],\n",
       "    num_rows: 223\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90% train, 10% test + validation\n",
    "train_testvalid = raw_datasets.train_test_split(test_size=0.1)\n",
    "\n",
    "raw_datasets = train_testvalid['test']\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3EtYfeHIrIz"
   },
   "source": [
    "To access an actual element, you need to select a split first, then give an index:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAWdqcUBIrJC"
   },
   "source": [
    "You can call its `compute` method with your predictions and labels, which need to be list of decoded strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "UmvbnJ9JIrJd"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_piple_metrics(decoded_preds, decoded_labels):\n",
    "        \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\furyx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Loads the model'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "nltk.download('punkt')\n",
    "\"\"\"Loads the model\"\"\"\n",
    "# Initialize the HuggingFace summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "model = summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_summary(model, text, min_length=3, max_length=50):\n",
    "    \"\"\"default huggingface transformer pipeline summary task\"\"\"\n",
    "    assert model\n",
    "    summarized = model(\n",
    "        text, min_length=min_length, max_length=max_length)\n",
    "    # print(summarized)\n",
    "    return summarized[0][\"summary_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hereford win 3-1 on penalties.  Rovers took the lead on 59 minutes as Michael McIndoe's corner found Adriano Rigoglioso, whose stunning volley soared into the top right of the net. Danny Williams equalised for the hosts after 72 minutes with a crisp finish from just insist the penalty box. McIndoe saw an extra-time penalty saved, giving Mills the chance to net the winning penalty.  Mawson, Travis, Mkandawire, James, Robinson, Daniel Williams, Stanley, Hyde (Pitman 105), Purdie (Mills 83), Brown, Stansfield (Green 102). Subs Not Used: Smith, Scott.  James.  Daniel Williams 72.  Ingham, Mulligan, Fenton, Morley, Priet (Ryan 79), McIndoe, Ravenhill (Price 90), Rigoglioso, Tierney (Jackson 79), Beardsley, Coppinger. Subs Not Used: Warrington, Maloney.  Rigoglioso 59.  1,375  T Parkes (W Midlands). \""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 512, but you input_length is only 231. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Adriano Rigoglioso gave Rovers the lead on 59 minutes with a stunning volley . Danny Williams equalised for the hosts with a crisp finish from just outside the penalty box . Michael McIndoe saw an extra-time penalty saved, giving Mills the chance to net the winner .'}]\n"
     ]
    }
   ],
   "source": [
    "raw_datasets['article'][0]\n",
    "summary = transformer_summary(model, raw_datasets['article'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Adriano Rigoglioso gave Rovers the lead on 59 minutes with a stunning volley . Danny Williams equalised for the hosts with a crisp finish from just outside the penalty box . Michael McIndoe saw an extra-time penalty saved, giving Mills the chance to net the winner .'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 4.2105, 'rouge2': 0.0, 'rougeL': 4.2105, 'rougeLsum': 4.2105}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_piple_metrics([summary], [raw_datasets['summary'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 512, but you input_length is only 130. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 119. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 100. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 102. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 134. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 117. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 127. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 98. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 126. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 106. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 133. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 126. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 102. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 119. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 106. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 106. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 157. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 97. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 99. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 139. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 128. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 134. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 98. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 99. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 119. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 99. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 106. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 143. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 100. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 99. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 117. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 130. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 106. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 97. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 117. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 119. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 119. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 103. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 119. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 109. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 103. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 101. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 110. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 106. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 98. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 102. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 103. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 100. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 110. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 117. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 97. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 98. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 98. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 101. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 124. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 124. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 110. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 103. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 127. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 120. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 97. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 122. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 111. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 118. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 102. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 117. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 113. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 119. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 112. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 105. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 102. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 107. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 108. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 117. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 115. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 512, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for row in raw_datasets:\n",
    "    article = ''\n",
    "    article = row['article'][:512] if len(\n",
    "        row['article']) > 512 else row['article']\n",
    "\n",
    "    summary = transformer_summary(model, article, max_length=len(article))\n",
    "\n",
    "    metrics.append(compute_piple_metrics([summary], [row['summary']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default transformer fmeasure: 24.261487892376678\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "fmeasure = array([k['rougeL'] for k in metrics]).mean()\n",
    "print('Default transformer fmeasure: ' + str(fmeasure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = updated_dataset.map(compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint) # t5-small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "By default, the call above will use one of the fast tokenizers (backed by Rust) from the ðŸ¤— Tokenizers library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "You can directly call this tokenizer on one sentence or a pair of sentences:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qo_0B1M2IrJM"
   },
   "source": [
    "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
    "\n",
    "Instead of one sentence, we can pass along a list of sentences:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare the targets for our model, we need to tokenize them inside the `as_target_tokenizer` context manager. This will make sure the tokenizer uses the special tokens corresponding to the targets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "If you are using one of the five T5 checkpoints we have to prefix the inputs with \"summarize:\" (the model can also translate and it needs the prefix to know which task it has to perform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We can then write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # x var for summarization. Column article.\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets y. We are using column title as label.\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "DDtsaJeVIrJT",
    "outputId": "aa4734bf-4ef5-4437-9948-2c16363da719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.76ba/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "Even better, the results are automatically cached by the ðŸ¤— Datasets library to avoid spending time on this step the next time you run your notebook. The ðŸ¤— Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ðŸ¤— Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "TlqNaB8jIrJW",
    "outputId": "84916cf3-6e6c-47f3-d081-032ec30a4132"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "Note that  we don't get a warning like in our classification example. This means we used all the weights of the pretrained model and there is no randomly initialized head in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "To instantiate a `Seq2SeqTrainer`, we will need to define three more things. The most important is the [`Seq2SeqTrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the cell and customize the weight decay. Since the `Seq2SeqTrainer` will save the model regularly and our dataset is quite large, we tell it to make three saves maximum. Lastly, we use the `predict_with_generate` option (to properly generate summaries) and activate mixed precision training (to go a bit faster).\n",
    "\n",
    "The last argument to setup everything so we can push the model to the [Hub](https://huggingface.co/models) regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the `hub_model_id` argument to set the repo name (it needs to be the full name, including your namespace: for instance `\"sgugger/t5-finetuned-xsum\"` or `\"huggingface/t5-finetuned-xsum\"`).\n",
    "\n",
    "Then, we need a special kind of data collator, which will not only pad the inputs to the maximum length in the batch, but also the labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sZOdRlRIrJd"
   },
   "source": [
    "The last thing to define for our `Seq2SeqTrainer` is how to compute the metrics from the predictions. We need to define a function for this, which will just use the `metric` we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now upload the result of the training to the Hub, just execute this instruction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `\"your-username/the-name-you-picked\"` so for instance:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"sgugger/my-awesome-model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuned_summary(text, min_length=12, max_length=512):\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            \"furyhawk/t5-base-finetuned-bbc\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"furyhawk/t5-base-finetuned-bbc\")\n",
    "\n",
    "        # T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "        inputs = tokenizer(\"summarize: \" + text,\n",
    "                           return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        outputs = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs['attention_mask'], max_length=max_length,\n",
    "                                 min_length=min_length, length_penalty=0.1, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        summary = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hereford win 3-1 on penalties. Rovers took the lead on 59 minutes as Michael McIndoe's corner found Adriano Rigoglioso, whose stunning volley soared into the top right of the net. Danny Williams equalised for the hosts after 72 minutes with a crisp finish from just insist the penalty box.\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = finetuned_summary(raw_datasets['article'][0])\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 42.8571, 'rouge2': 37.5, 'rougeL': 38.7755, 'rougeLsum': 38.7755}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_piple_metrics(summary, [raw_datasets['summary'][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for row in raw_datasets:\n",
    "    article = ''\n",
    "    article = row['article'][:512] if len(\n",
    "        row['article']) > 512 else row['article']\n",
    "\n",
    "    summary = finetuned_summary(article, max_length=len(article))\n",
    "    # print(summary)\n",
    "\n",
    "    metrics.append(compute_piple_metrics(summary, [row['summary']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned_summary fmeasure: 30.69969686098655\n"
     ]
    }
   ],
   "source": [
    "fmeasure = array([k['rougeL'] for k in metrics]).mean()\n",
    "print('finetuned_summary fmeasure: ' + str(fmeasure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_summary(text, min_length=12, max_length=512):\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            \"t5-base\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"t5-base\")\n",
    "\n",
    "        # T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "        inputs = tokenizer(\"summarize: \" + text,\n",
    "                           return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        outputs = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs['attention_mask'], max_length=max_length,\n",
    "                                 min_length=min_length, length_penalty=0.1, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        summary = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for row in raw_datasets:\n",
    "    article = ''\n",
    "    article = row['article'][:512] if len(\n",
    "        row['article']) > 512 else row['article']\n",
    "\n",
    "    summary = t5_summary(article, max_length=len(article))\n",
    "    # print(summary)\n",
    "\n",
    "    metrics.append(compute_piple_metrics(summary, [row['summary']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5_summary fmeasure: 20.595196412556053\n"
     ]
    }
   ],
   "source": [
    "fmeasure = array([k['rougeL'] for k in metrics]).mean()\n",
    "print('t5_summary fmeasure: ' + str(fmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Summarization",
   "provenance": []
  },
  "interpreter": {
   "hash": "5caea8df2d6b3afe4c6a8fa5e4ec8aa952f5ed6f914beaca74edf16901303bb7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('text': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
